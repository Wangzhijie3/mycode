## LFM(Latent Factor Model)

设想一下这样一个场景，Ben，Tom，John，Fred对六种商品进行了评价，评分越高代表对该商品越喜欢，0表示未评价。

![欧式距离](../../images/lfm1)

我们可以转化为矩阵A表示：

![欧式距离](../../images/lfm2)

我们不妨假定用户根据啥给评的分，

假如这个商品是火龙果，那么用户对它评分肯定根据什么评得呀，假如根据产地、价格、口感、包装。。。。等等，假设现在有2个隐变量产地、价格，那么我们可以将这个6*4得矩阵分解一下，分成6*2得商品-隐变量矩阵和2*4的隐变量-用户矩阵，我们回头看看这么分解合不合理。

![欧式距离](../../images/lfm3)

接着我们用拉格朗日乘子法建立目标函数：

![欧式距离](../../images/lfm4)

我们对u和v求偏导：

![欧式距离](../../images/lfm5)

其中uv无法消除掉，需要互相更新，我们令导数等于0，就可以根据梯度不断的优化直到收敛。

最后得到用户-隐变量矩阵：

![欧式距离](../../images/lfm6)

商品-隐变量矩阵：

![欧式距离](../../images/lfm7)

k表示隐变量个数，是需要交叉验证的，或者根据领域知识来确定。

另外如果在矩阵分解过程中，有负权值的话，虽然可以解释，然是需要避免。

### 影响LFM算法的不同情况

- 样本选取  负样本比正样本多得多，因此选取充分展现但用户无点击的item作为负样本；

- 模型参数：隐特征F (10~32之间)、正则参数 $\lambda$  (0.01~0.05之间)、learning rate 学习率$\beta$ (0.01~0.05之间)

### LFM vs item CF

- 理论基础 LFM使用隐特征基于平方误差训练监督学习模型；

- 离线计算空间时间复杂度 LFM需要的空间复杂度更低；

- 在线推荐与推荐解释。







