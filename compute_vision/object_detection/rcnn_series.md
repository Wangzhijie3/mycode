## RCNN

RCNN的过程分4个阶段：

- 候选区域提出阶段（Proposal）：采用selective-search方法，从一幅图像生成1K~2K个候选区域；
- 特征提取：对每个候选区域，使用CNN进行特征提取；
- 分类：每个候选区域的特征放入分类器SVM，得到该候选区域的分类结果；
- 回归：候选区域的特征放入回归器，得到bbox的修正量。

### 候选区域提出阶段所产生的结果尺寸不同

由于RCNN特征提取阶段采用的是AlexNet，其最后两层是全连接层fc6和fc7，所以必须保证输入的图片尺寸相同。

而候选区域所产生的结果尺寸是不相同的。为此，论文中作者采用了多种方式对图片进行放缩（各向同性、各向异性、加padding），最后经过对比实验确定各向异性加padding的放缩方式效果最好。

### 分类器SVM

论文中，单个SVM实现的是二分类，分类器阶段由多个SVM组合而成。比如总共有20种不同的物体（加1种背景），那么分类阶段必须要有21个SVM：第1个SVM的输出是该候选区域属于分类1的概率；第2个SVM的输出是该候选区域属于分类2的概率；……；第21个SVM的输出是该候选区域属于背景的概率。

对21个SVM的输出结果进行排序，哪个输出最大，候选区域就属于哪一类。比如，对于某个候选区域，第21个SVM的输出最大，那么就将该候选区域标为背景。

### 分类器的输入是？回归器的输入是？

分类器的输入是特征提取器AlexNet的fc6的输出结果，回归器的输入是特征提取器AlexNet的pool5的输出结果。

之所以这样取输入，是因为，分类器不依赖坐标信息，所以取fc6全连接层的结果是没有问题的。但是回归器依赖坐标信息（要输出坐标的修正量），必须取坐标信息还没有丢失前的层。而fc6全连接层已经丢失了坐标信息。

### 正负样本的选择

正负样本是必须要考虑的问题。论文的做法是每个batch所采样的正负样本比为1：3。当然这个比例是可以变化的，这个系列的后续改进就把正负样本比变为了1：1。

如果之前没有接触过类似问题的话，是比较容易想当然地认为训练特征提取器、分类器、回归器时，就是把候选区域生成阶段的所有候选区域都放入训练。这样的思路是错的。一张图片中，背景占了绝大多数地方，这样就导致训练用的正样本远远少于负样本，对训练不利。

正确的做法是对所有候选区域进行随机采样，要求采样的结果中正样本有x张，负样本y张，且保证x与y在数值上相近。（对于一些问题，不大容易做到x:y = 1:1，但至少x与y应该在同一数量级下）

### 训练

前面提到RCNN分为4个阶段：Proposal阶段、特征提取阶段、分类阶段、回归阶段。这4个阶段都是相互独立训练的。

首先，特征提取器是AlexNet，将它的最后一层fc7进行改造，使得fc7能够输出分类结果。Proposal阶段对每张图片产生了1k~2k个候选区域，把这些图片依照正负样本比例喂给特征提取器，特征提取器fc7输出的分类结果与标签结果进行比对，完成特征提取器的训练。特征提取器的训练完成后，fc7层的使命也完成了，后面的分类器和回归器只会用到fc6、pool5的输出。

然后，Proposal和特征提取器已经训练完毕了。把它们的结果fc6，输入到分类器SVM中，SVM输出与标签结果比对，完成SVM的训练。

最后，回归器的训练也和SVM类似，只不过回归器取的是pool5的结果。

为什么不能同时进行上面3步的训练？因为特征提取器是CNN，分类器是SVM，回归器是脊回归器，不属于同一体系，无法共同训练。甚至在测试时，也需要把每一阶段的结果先保存到磁盘，再喂入下一阶段。这是非常麻烦的一件事。

这里顺便提一下脊回归器，脊回归器又称岭回归器（Ridge Regression），表示该回归器加了L2正则化。


###  Proposal的每个候选区域单独提取特征很慢

Proposal阶段会产生1k~2k个候选区域，每个候选区域都独立提取特征的话，那相当于每幅图片都要进行1k~2k次CNN。

## SPP Net

它的特点有两个:

- 1.结合空间金字塔方法实现CNNs的对尺度输入。
一般CNN后接全连接层或者分类器，他们都需要固定的输入尺寸，因此不得不对输入数据进行crop或者warp，这些预处理会造成数据的丢失或几何的失真。SPP Net的第一个贡献就是将金字塔思想加入到CNN，实现了数据的多尺度输入。

如下图所示，在卷积层和全连接层之间加入了SPP layer。此时网络的输入可以是任意尺度的，在SPP layer中每一个pooling的filter会根据输入调整大小，而SPP的输出尺度始终是固定的。

![欧式距离](../../images/rcnn1.jpg)

- 2.只对原图提取一次卷积特征
在R-CNN中，每个候选框先resize到统一大小，然后分别作为CNN的输入，这样是很低效的。
所以SPP Net根据这个缺点做了优化：只对原图进行一次卷积得到整张图的feature map，然后找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层。节省了大量的计算时间，比R-CNN有一百倍左右的提速。

![欧式距离](../../images/rcnn2.jpg)

## Fast-RCNN

Fast-RCNN将特征提取器、分类器、回归器合在了一起，都用CNN实现。

其次，Fast-RCNN对整张图片进行特征提取，再根据候选区域在原图中的位置挑选特征。针对特征数目不同的问题，Fast-RCNN加入了ROI层，使得经过ROI层后，特征的数目相同。

![欧式距离](../../images/rcnn3.png)

### Fast 

将特征提取器、分类器、回归器合并，使得训练过程不需要再将每阶段结果保存磁盘单独训练，可以一次性完成训练，加快了训练速度。这是Fast之一。

对整张图片进行特征提取，用ROI层处理候选区域的特征，使得原本每一个候选区域都要做一次特征提取，变为了现在一整张图片做一次特征提取。训练速度（8.8倍）和测试速度（146倍）都大大加快，这是Fast之二。


### ROI

提出了一个可以看做单层sppnet的网络层，叫做ROI Pooling，这个网络层可以把不同大小的输入映射到一个固定尺度的特征向量，而我们知道，conv、pooling、relu等操作都不需要固定size的输入，因此，在原始图片上执行这些操作后，虽然输入图片size不同导致得到的feature map尺寸也不同，不能直接接到一个全连接层进行分类，但是可以加入这个神奇的ROI Pooling层，对每个region都提取一个固定维度的特征表示，再通过正常的softmax进行类型识别。

另外，之前RCNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast-RCNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。

### 分类器和回归器的实现细节

分类器应该都能想到，用的softmax代替SVM。

回归器求出（x,y,w,h）4个量，分别代表定位框左上角的坐标xy、宽度w、高度h，损失函数用的是Smooth-L1。

### Proposal阶段看上去有点违和

发展到Fast-RCNN，后续3个阶段都是CNN完成的了，只剩下Proposal阶段还没有用CNN方式解决。Proposal阶段的结果还是需要先保存到磁盘，再喂入后续阶段，有点违和。


## Faster-RCNN

Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。那我们能不能找出一个更加高效的方法来求出这些候选框呢？
解决：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。
做这样的任务的神经网络叫做Region Proposal Network(RPN)。

![欧式距离](../../images/rcnn4.png)

### RPN网络是如何工作的？

整张图片经过特征提取，得到FeatureMap；将FeatureMap中的每一点按照视野域找到原图中对应的位置，称为Anchor；每个Anchor生成不同大小不同长宽比的多个候选区域。

回忆下selective-search的候选区域生成方式，它是按照颜色和纹理不断合并得到候选区域的，候选区域的产生没有规律，而RPN是每个Anchor都有对应的固定数量的候选区域，规律很明显。

理论上说，selective-search生成候选区域的方式更符合我们的直觉，而实验结果，在Faster-RCNN中RPN并不比selective-search差

### RPN 具体做法

- 将RPN放在最后一个卷积层的后面
- RPN直接训练得到候选区域

### RPN简介

- 在feature map上滑动窗口
- 建一个神经网络用于物体分类+框位置的回归
- 滑动窗口的位置提供了物体的大体位置信息
- 框的回归提供了框更精确的位置

![欧式距离](../../images/rcnn5.png)

一种网络，四个损失函数;
- RPN calssification(anchor good.bad)
- RPN regression(anchor->propoasal)
- Fast R-CNN classification(over classes)
- Fast R-CNN regression(proposal ->box)

### 为什么是Faster

容现在RPN网络可以与其他3个阶段共用同一个特征提取结果了，省掉了selective-search的时间。而事实上，selective-search是非常慢的，所以叫Faster。

## Mask-RCNN

### 为什么叫mask

Faster-RCNN网络的最后分别是分类网络和回归网络两条路并行，Mask-RCNN则是再加一条Mask网络与它们并行。

Mask网络的实现是FCN网络，这也是语义分割领域中非常经典的网络结构。

由于Mask网络的加入，Mask-RCNN不仅能处理物体检测问题，还能处理语义分割问题。

### 还有哪些细节上的变化？

首先是ROI层变为了ROIAlign，目的是一样的。那为什么要加入ROIAlign呢？这是因为ROI层会有对齐问题，对齐问题在分类和框选时影响不大，但在语义分割需要严格依赖每个像素点的坐标时，影响会很大。ROIAlign能够解决对齐问题。

然后是特征提取网络改为了ResNet101+FPN


参考：
https://imlogm.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/rcnn/?nsukey=swqWwCDrxywXS9f2xKtw%2FgRnan0bFvzi51Auv4JWEO%2FZw0%2BRpBRrmUi65RLZ5lYjfR%2F36mrEc4zCmMxzRb7068ZvJqToRGaawFMZteBeSyYV55mB6cQvxjIJMe0BWx%2F7dmA4l0ZyNbkhi308kUJ7s90f9bTm845u8nFozTaLEUiYFpq2Y0ri658gLvdkYB2POP01DyUZG2yl6dSoeeh9pw%3D%3D
https://www.cnblogs.com/skyfsm/p/6806246.html
https://blog.csdn.net/linolzhang/article/details/54344350